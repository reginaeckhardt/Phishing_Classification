{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally we used a maximum length of 70 for the emails, which might be too short\n",
    "# a length of 350 showed the best accuracy compared to various email lengths\n",
    "#max_length = 2000\n",
    "#trainX =pad_sequences(encoded_train_texts,maxlen=max_length_cnn,padding=\"post\",truncating=\"post\")\n",
    "#testX =pad_sequences(encoded_test_texts,maxlen=max_length_cnn,padding=\"post\",truncating=\"post\")\n",
    "#trainX_ws =pad_sequences(encoded_train_texts_ws,maxlen=max_length_cnn,padding=\"post\",truncating=\"post\")\n",
    "#testX_ws =pad_sequences(encoded_test_texts_ws,maxlen=max_length_cnn,padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs1 = Input(shape=(max_length,))\n",
    "embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "conv1 = Conv1D(filters=48, kernel_size=4, activation='relu')(embedding1)\n",
    "drop1 = Dropout(0.5)(conv1)\n",
    "pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "flat1 = Flatten()(pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = Input(shape=(max_length,))\n",
    "embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
    "conv2 = Conv1D(filters=48, kernel_size=6, activation='relu')(embedding2)\n",
    "drop2 = Dropout(0.5)(conv2)\n",
    "pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "flat2 = Flatten()(pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs3 = Input(shape=(max_length,))\n",
    "embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
    "conv3 = Conv1D(filters=48, kernel_size=8, activation='relu')(embedding3)\n",
    "drop3 = Dropout(0.5)(conv3)\n",
    "pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "flat3 = Flatten()(pool3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = concatenate([flat1, flat2, flat3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(10, activation='relu')(merged)\n",
    "#outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "outputs = Dense(2, activation='softmax')(dense1)\n",
    "model_cnn = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Regina Eckhardt\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "history_cnn_1 = model_cnn.fit([trainX,trainX,trainX], array(y_train1), validation_data=([testX,testX,testX],y_test1), epochs=50, batch_size=16, verbose=2,callbacks=[EarlyStopping(patience=3),mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = [1,2,3]\n",
    "#batch_size = [8,16]\n",
    "#param_grid = dict(batch_size=batch_size,epochs=epochs)\n",
    "#grid = GridSearchCV(estimator = model_cnn, param_grid = param_grid, n_jobs=-1,cv=3,scoring=\"accuracy\")\n",
    "#grid_result = grid.fit(trainX, array(y_train1))\n",
    "#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 100)     1000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     1000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 100, 100)     1000000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 97, 48)       19248       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 95, 48)       28848       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 93, 48)       38448       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 97, 48)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 95, 48)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 93, 48)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 48, 48)       0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 47, 48)       0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 46, 48)       0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2304)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2256)         0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2208)         0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6768)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           67690       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            22          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,154,256\n",
      "Trainable params: 3,154,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_cnn.summary())\n",
    "#plot_model(model_cnn, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to define a predict function that includes the transformation of the list of texts to a vector of numerical values\n",
    "def predict_cnn(text):\n",
    "    stem_texts = [stemSentence(x) for x in text]\n",
    "    encoded_texts = [one_hot(t,vocab_size) for t in stem_texts]\n",
    "    encoded_input = pad_sequences(encoded_texts,maxlen=max_length,padding=\"post\",truncating=\"post\")\n",
    "    return model_cnn.predict([encoded_input,encoded_input,encoded_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_anchor_cnn = AnchorText(nlp, predict_cnn)\n",
    "explainer_lime = LimeTextExplainer(class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
