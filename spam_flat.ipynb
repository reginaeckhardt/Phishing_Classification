{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = os.path.dirname(os.path.abspath(\"spam-flat3.csv\"))\n",
    "\n",
    "def load_data(vocab_size):\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    path = os.path.join(PATH, \"spam-flat3.csv\")\n",
    "    mydata = pd.read_csv(path)\n",
    "    with_subject = mydata[\"subject\"] + \" \" + mydata[\"bodyHtml\"]\n",
    "    with_subject = with_subject.fillna(\"Ignore\")\n",
    "    X_ws = with_subject.tolist()\n",
    "    mydata.loc[mydata['phishing'].astype(str) == 'False','phishing'] = 0\n",
    "    mydata.loc[mydata['phishing'].astype(str) == 'True','phishing'] = 1\n",
    "    y = mydata['phishing'].astype(int).tolist()\n",
    "    X_ws_train,X_ws_test,y_train,y_test = train_test_split(X_ws,y,test_size=0.3,random_state=42)\n",
    "    trainX = preprocess_text(X_ws_train)\n",
    "    testX = preprocess_text(X_ws_test)\n",
    "    trainY = preprocess_label(y_train)\n",
    "    testY = preprocess_label(y_test)\n",
    "    return X_ws_train, X_ws_test, trainX, trainY, testX, testY\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.stem import PorterStemmer\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(PorterStemmer().stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "        return \"\".join(stem_sentence)\n",
    "\n",
    "def preprocess_text(data_x):\n",
    "    from keras.preprocessing.text import one_hot\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    max_length = 350\n",
    "    vocab_size = 10000\n",
    "    X_2 = [stemSentence(x) for x in data_x]\n",
    "    encoded_texts_ws = [one_hot(t,vocab_size) for t in X_2]\n",
    "    padded_texts_ws =pad_sequences(encoded_texts_ws,maxlen=max_length,padding=\"post\",truncating=\"post\")\n",
    "    return padded_texts_ws\n",
    "\n",
    "def preprocess_label(data_y):\n",
    "    import numpy as np\n",
    "    y_1 =[]\n",
    "    for x in data_y:\n",
    "        if x==0:\n",
    "            y_1.append([1,0])\n",
    "        else:\n",
    "            y_1.append([0,1])\n",
    "    y_1 = np.vstack(y_1)\n",
    "    return y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
