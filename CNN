from tensorflow import keras
import tensorflow as tf
import sklearn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from keras.preprocessing import sequence
from keras.preprocessing.text import Tokenizer
from numpy import array
from keras.preprocessing.text import one_hot
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import InputLayer
from keras.layers import Conv1D,MaxPooling1D
from keras.layers.embeddings import Embedding
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D
from pickle import load
from keras.utils.vis_utils import plot_model
from keras.utils import to_categorical
from keras.models import Model
from keras.layers import Input
from keras.layers import Embedding
from keras.layers.convolutional import AveragePooling1D
from keras.layers.merge import concatenate
from keras.layers import LSTM
from keras import backend as K
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
datapath="C:/Users/Regina Eckhardt/Documents/Uni/Masterarbeit/"
filepath=datapath+"spam-flat3.csv"
mydata=pd.read_csv(filepath)

texts = mydata['text'].tolist()

mydata.loc[mydata['phishing'].astype(str) == 'False','phishing'] = 0
mydata.loc[mydata['phishing'].astype(str) == 'True','phishing'] = 1

label = mydata['phishing'].astype(int).tolist()
sum = mydata['phishing'].sum()

final_data = mydata[mydata['phishing'].isin([0,1])]

X = texts
y = label
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)

vocab_size = 10000
encoded_train_texts = [one_hot(t,vocab_size) for t in X_train]
encoded_test_texts = [one_hot(t,vocab_size) for t in X_test]
#print(encoded_train_texts[:2])
max_length = 70
padded_train_docs = pad_sequences(encoded_train_texts,maxlen=max_length,padding="post")
padded_test_docs = pad_sequences(encoded_test_texts,maxlen=max_length,padding="post")

def encode_text(lines, length):
     padded = pad_sequences(lines, maxlen=length, padding='post')
     return padded
#encode data
trainX = encode_text(encoded_train_texts, max_length)
testX = encode_text(encoded_test_texts, max_length)
# print(trainX)
trainX = np.expand_dims(trainX, axis=2)
testX = np.expand_dims(testX, axis=2)
#create model
model = Sequential()
model.add(Conv1D(48, kernel_size=4, activation='relu', input_shape=(70,1)))
model.add(Dropout(0.5))
model.add(MaxPooling1D(pool_size=2))
model.add(Conv1D(48, kernel_size=6, activation='relu'))
model.add(Dropout(0.5))
model.add(MaxPooling1D(pool_size=2))
model.add(Conv1D(filters=48, kernel_size=8, activation='relu'))
model.add(Dropout(0.5))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
result = model.fit(trainX, y_train, validation_data=(testX, y_test), epochs=5)

print(model.summary())
loss = result.history['loss']
val_loss = result.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, color='red', label='Training loss')
plt.plot(epochs, val_loss, color='green', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

inp = model.input                                           
outputs = [layer.output for layer in model.layers]          
functors = [K.function([inp], [out]) for out in outputs]  

# Testing
test = np.random.random((70,1))[np.newaxis,...]
layer_outs = [func([test]) for func in functors]
print(layer_outs[0])
print(layer_outs[1])
print(layer_outs[2])
